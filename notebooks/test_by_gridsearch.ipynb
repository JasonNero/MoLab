{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(grid: dict[str, list]):\n",
    "    \"\"\"Takes a dictionary of lists. Each list is a parameter to search over.\n",
    "    The search/test space is the cartesian product of all the lists.\n",
    "    \"\"\"\n",
    "    product = list(itertools.product(*grid.values()))\n",
    "    for i, params in enumerate(product):\n",
    "        data = dict(zip(grid.keys(), params))\n",
    "        print(f\"========== Infer by Grid Search [{i+1}/{len(product)}] ==========\")\n",
    "        pprint(data)\n",
    "        print(\"================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `random_joints` Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1: Benchmark-Clip with IK Methods and Editable Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Infer by Grid Search [1/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': True,\n",
      " 'jacobian_ik': True,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': True,\n",
      " 'jacobian_ik': True,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [3/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [4/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [5/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': True,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [6/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': True,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [7/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [8/8] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_grid_1 = {\n",
    "    \"bvh_path\": [\"dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh\"],\n",
    "    \"edit_mode\": [\"benchmark_clip\"],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [True, False],\n",
    "    \"jacobian_ik\": [True, False],\n",
    "    \"editable_features\": [\"pos_rot\", \"pos_rot_vel\"],\n",
    "}\n",
    "\n",
    "grid_search(test_grid_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "\n",
    "- `IK` Methoden\n",
    "  - `jacobian` geht kaputt beim Umdrehen\n",
    "  - `basic` Root/Legs flippen kurz bevor der Charakter bei z=0 stehen bleibt\n",
    "- `editable_features`\n",
    "  - `pos` geht kaputt beim Umdrehen\n",
    "  - `pos_rot` \n",
    "    - innerhalb t_obs hängts hinterher\n",
    "    - innerhalb t_sample stimmt die Root Position ABER Footsliding\n",
    "  - `pos_rot_vel` \n",
    "    - innerhalb t_obs stimmt die Root Position\n",
    "    - innerhalb t_sample stimmt hängts etwas hinterher dafür KEIN Footsliding\n",
    "- `foot_ik` bringt gar nicht soo viel\n",
    "  - Rutscht trotzdem, vllt lohnt es sich mal den Threshold zu erhöhen\n",
    "  - Alternativ mal die Foot Contact Flags zu benutzen die das Modell vorhersagt\n",
    " \n",
    " ### Takeaways\n",
    "\n",
    "- [ ] Basic IK Flipping fixen\n",
    "  - [ ] Evtl reicht hier ein Euler Filter / Euler Unrolling\n",
    "- [ ] Jacobian hat evtl ein hardcoded forward Vector?\n",
    "- [ ] Methoden überlegen wie die Velocity gefaked werden kann bei einzelnen Keyframes\n",
    "  - [ ] Evtl doch mal statt `stepped` auch einen `linear` Initializer probieren\n",
    "- [ ] Foot IK Threshold erhöhen und auch mal die Foot Contact Flags benutzen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 2: Benchmark-Clip with Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Infer by Grid Search [1/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'imputate': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'stop_imputation_at': 0}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'imputate': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'stop_imputation_at': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [3/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'imputate': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'stop_imputation_at': 10}\n",
      "================================================\n",
      "========== Infer by Grid Search [4/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'imputate': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'stop_imputation_at': 100}\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_grid_2 = {\n",
    "    \"bvh_path\": [\n",
    "        \"dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh\"\n",
    "    ],\n",
    "    \"edit_mode\": [\"benchmark_clip\"],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot_vel\"],\n",
    "\n",
    "    \"imputate\": [True],\n",
    "    \"stop_imputation_at\": [0, 1, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search(test_grid_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "- `stop_imputation_at=0`\n",
    "  - innerhalb t_obs: perfekt\n",
    "  - innerhalb t_sample: Root Sprung nach hinten, Rotationen aber okay\n",
    "- `stop_imputation_at=1`\n",
    "  - innerhalb t_obs: leicht hinterher\n",
    "  - innerhalb t_sample: \n",
    "    - fast deckungsgleich mit `0`\n",
    "    - aber halt ohne den Sprung weil t_obs schon leicht hintendran ist und sich der Offset langsam auf und abbaut\n",
    "- `stop_imputation_at=10`\n",
    "  - innerhalb t_obs: wie bei `1`\n",
    "  - innerhalb t_sample: wie bei `1` mit etwas mehr Offset\n",
    "- `stop_imputation_at=100`\n",
    "  - innerhalb t_obs: wie bei `10`\n",
    "  - innerhalb t_sample: sehr ähnlich aber leicht besser als `10`\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "- Imputate mit Stop 0 ist wegen des Sprungs unbrauchbar\n",
    "- Imputate mit Stop >= 1 könnte in Sonderfällen interessant sein\n",
    "  - [ ] Mal bei `benchmark_sparse` testen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 3: Benchmark-Clip with Reconstruction Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Infer by Grid Search [1/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 1,\n",
      " 'stop_recguidance_at': 0}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 5,\n",
      " 'stop_recguidance_at': 0}\n",
      "================================================\n",
      "========== Infer by Grid Search [3/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 20,\n",
      " 'stop_recguidance_at': 0}\n",
      "================================================\n",
      "========== Infer by Grid Search [4/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 1,\n",
      " 'stop_recguidance_at': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [5/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 5,\n",
      " 'stop_recguidance_at': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [6/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 20,\n",
      " 'stop_recguidance_at': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [7/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 1,\n",
      " 'stop_recguidance_at': 10}\n",
      "================================================\n",
      "========== Infer by Grid Search [8/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 5,\n",
      " 'stop_recguidance_at': 10}\n",
      "================================================\n",
      "========== Infer by Grid Search [9/9] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 20,\n",
      " 'stop_recguidance_at': 10}\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_grid_3 = {\n",
    "    \"bvh_path\": [\n",
    "        \"dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh\"\n",
    "    ],\n",
    "    \"edit_mode\": [\"benchmark_clip\"],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot_vel\"],\n",
    "\n",
    "    \"reconstruction_guidance\": [True],\n",
    "    \"stop_recguidance_at\": [0, 1, 10],\n",
    "    \"reconstruction_weight\": [1, 5, 20],\n",
    "}\n",
    "\n",
    "grid_search(test_grid_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "- `stop=0`\n",
    "  - `w=1`\n",
    "    - innerhalb t_obs: Nah an Original, leicht dahinter\n",
    "    - innerhalb t_sample: Leichter Sprung Richtung Original\n",
    "  - `w=5`\n",
    "    - innerhalb t_obs: Nah an Original, leicht dahinter\n",
    "    - innerhalb t_sample: Merklicher Sprung Richtung Original\n",
    "  - `w=10`\n",
    "    - innerhalb t_obs: Nah an Original, leicht dahinter\n",
    "    - innerhalb t_sample: Overshoot und Moonwalk \n",
    "- `stop=1`\n",
    "  - Kein Sprung mehr\n",
    "  - Höhere `w` Werte sind näher an Original, aber beinahe unmerklich\n",
    "- `stop=10`\n",
    "  - Unmerklicher Unterschied zu `stop=1`\n",
    "\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "- Auch hier ist `stop=0` unbrauchbar wegen des Sprungs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 4: Benchmark-Clip with Reconstruction Guidance and Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Infer by Grid Search [1/2] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'imputate': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 1,\n",
      " 'stop_imputation_at': 1,\n",
      " 'stop_recguidance_at': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/2] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'imputate': True,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'reconstruction_guidance': True,\n",
      " 'reconstruction_weight': 5,\n",
      " 'stop_imputation_at': 1,\n",
      " 'stop_recguidance_at': 1}\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_grid_5 = {\n",
    "    \"bvh_path\": [\n",
    "        \"dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh\"\n",
    "    ],\n",
    "    \"edit_mode\": [\"benchmark_clip\"],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot_vel\"],\n",
    "\n",
    "    \"reconstruction_guidance\": [True],\n",
    "    \"stop_recguidance_at\": [1],\n",
    "    \"reconstruction_weight\": [1, 5],\n",
    "\n",
    "    \"imputate\": [True],\n",
    "    \"stop_imputation_at\": [1],\n",
    "}\n",
    "\n",
    "grid_search(test_grid_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "- Beides zusammen liefert keinen Mehrwert\n",
    "- `w=5` ist besser als `w=1` (wie erwartet)\n",
    "\n",
    "- Inferenz mit beidem zusammen dauert 3:30 statt 1:50 min ...\n",
    "\n",
    "\n",
    "| Method     | Time |\n",
    "|------------|------|\n",
    "| Normal     | 1:50 |\n",
    "| Imputation | 1:50 |\n",
    "| Recguide   | 3:18 |\n",
    "| Both       | 3:30 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 5: benchmark_sparse & sparse keyframes via packed_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Infer by Grid Search [1/2] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_sparse',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/2] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_sparse',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [1/2] ==========\n",
      "{'editable_features': 'pos_rot',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'packed_motion': None}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/2] ==========\n",
      "{'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1,\n",
      " 'packed_motion': None}\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_grid_5a = {\n",
    "    \"bvh_path\": [\n",
    "        \"dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh\"\n",
    "    ],\n",
    "    \"edit_mode\": [\"benchmark_sparse\"],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot\", \"pos_rot_vel\"],\n",
    "}\n",
    "test_grid_5b = {\n",
    "    \"packed_motion\": [None],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot\", \"pos_rot_vel\"],\n",
    "}\n",
    "\n",
    "grid_search(test_grid_5a)\n",
    "grid_search(test_grid_5b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "- `benchmark_sparse`\n",
    "  - Bei `pos_rot` bleibt der Character sehr weit hinterher\n",
    "  - Bei `pos_rot_vel` passts ganz gut\n",
    "- `packed_motion`\n",
    "  - `pos_rot` besser als `pos_rot_vel`\n",
    "  - `pos_rot_vel` schwimmt bzw hat Footsliding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "- [ ] Definitiv eine Root Trajectory als Input anbieten, ggf einfach linear interpolieren?\n",
    "- [ ] Linear statt Stepped Initializer probieren\n",
    "- [ ] Nachschauen, ob beim Training der Feature-Mask==0 Bereich auch auf 0 gesetzt wird oder trotzdem noch Werte enthält"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `random_frames` Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 6: random_frames Model w/ `benchmark_clip`, `benchmark_sparse` and `packed_motion` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Infer by Grid Search [1/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [2/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_clip',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [3/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_sparse',\n",
      " 'editable_features': 'pos_rot',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n",
      "========== Infer by Grid Search [4/4] ==========\n",
      "{'bvh_path': 'dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh',\n",
      " 'edit_mode': 'benchmark_sparse',\n",
      " 'editable_features': 'pos_rot_vel',\n",
      " 'foot_ik': False,\n",
      " 'jacobian_ik': False,\n",
      " 'num_samples': 1}\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_grid_6 = {\n",
    "    \"bvh_path\": [\n",
    "        \"dataset/HumanML3D/bvh/test/001969_fromjoint100_a_man_walks_forward_then_turns_around_and_walks_back_before_facing_back_and_standing_still.bvh\"\n",
    "    ],\n",
    "    \"edit_mode\": [\"benchmark_clip\", \"benchmark_sparse\"],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot\", \"pos_rot_vel\"],\n",
    "}\n",
    "test_grid_5b = {\n",
    "    \"packed_motion\": [None],\n",
    "    \"num_samples\": [1],\n",
    "    \"foot_ik\": [False],\n",
    "    \"jacobian_ik\": [False],\n",
    "    \"editable_features\": [\"pos_rot\", \"pos_rot_vel\"],\n",
    "}\n",
    "\n",
    "grid_search(test_grid_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `random_frames > random_joints` bei vollen Keyframes\n",
    "  - Weniger Abstand zum Original, dafür Zittern bei sparse Keyframes\n",
    "- `random_joints > random_frames` bei sparse Keyframes\n",
    "  - Mehr Abstand zum Original, dafür kein Zittern bei sparse Keyframes\n",
    "\n",
    "- `pos_rot` haengt immer hinterher\n",
    "\n",
    "- `benchmark_clip`\n",
    "  - `pos_rot` slided komplett durch den Maskierten Bereich\n",
    "  - `random_frames` \n",
    "    - besseres Alignment mit Original\n",
    "    - fällt nicht zurück\n",
    "    - ruhigeres Verhalten bei Stillstand\n",
    "  - `random_joints` \n",
    "    - auch gutes Alignment mit Original \n",
    "    - fällt zurück sobald ausmaskiert\n",
    "    - mehr Zittern bei Stillstand\n",
    "\n",
    "- `mybenchclip` (entspricht `benchmark_clip` aber via `packed_motion`)\n",
    "  - `random_frames`\n",
    "    - Erst Footsliding, dann großer Fallschritt nach vorn\n",
    "  - `random_joints`\n",
    "    - Ein weiterer Schritt, dann Footsliding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `benchmark_clip` vs. `mybenchclip` (via `packed_motion`)\n",
    "  - `benchmark_clip` hat definitiv einen ungewollten Einfluss $>0$ auf die maskierten Bereiche\n",
    "  - `mybenchclip` hat keinen Einfluss auf die maskierten Bereiche (wie gewollt!)\n",
    "  - `mybenchclip` braucht irgendeine Velocity um die Lücken zu schließen, sonst gibts Footsliding\n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Experimente von oben (teilweise) wiederholen mit packed_motion_clip statt benchmark_clip\n",
    "  - [ ] Automatisieren: Export von 3 Varianten der packed motion (sparse_keyframes, full_keyframes, clip), dann an den InferenceWorker hängen und auf dem Cluster laufen lassen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condmdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
